{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers.legacy import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 1. Data Loading \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>dti</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>0.1998</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>24700.0</td>\n",
       "      <td>0.1998</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.1998</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>0.1998</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>104433.0</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>0.1998</td>\n",
       "      <td>3 years</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  home_ownership  annual_inc  loan_amnt     dti emp_length  label\n",
       "0       MORTGAGE     55000.0     3600.0  0.1998  10+ years      1\n",
       "1       MORTGAGE     65000.0    24700.0  0.1998  10+ years      1\n",
       "2       MORTGAGE     63000.0    20000.0  0.1998  10+ years      1\n",
       "3       MORTGAGE    110000.0    35000.0  0.1998  10+ years      1\n",
       "4       MORTGAGE    104433.0    10400.0  0.1998    3 years      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load datasets\n",
    "merged_data = pd.read_csv('/Users/eduardoangeli/Library/CloudStorage/OneDrive-Fanshawec.ca/Capstone/Dataset/merged_data.csv')\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding categorical columns ( encoding to categorical variables)\n",
    "encoded_data = pd.get_dummies(merged_data, columns=['home_ownership', 'emp_length'])\n",
    "\n",
    "# Splitting data and scaling features (split our data into training and test sets and scale, to normalizing data)\n",
    "X = encoded_data.drop(columns=['label']) \n",
    "y = merged_data['label']\n",
    "\n",
    "X = X.to_numpy()  # Convert to NumPy array if X is a DataFrame\n",
    "y = y.to_numpy()  # Convert to NumPy array if y is a DataFrame\n",
    "\n",
    "# Shuffle the data\n",
    "indices = np.arange(X.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "X_shuffled = X[indices]\n",
    "y_shuffled = y[indices]\n",
    "\n",
    "# Calculate the split index\n",
    "test_size = 0.2  # 20% for testing\n",
    "split_index = int(X.shape[0] * (1 - test_size))\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test = X_shuffled[:split_index], X_shuffled[split_index:]\n",
    "y_train, y_test = y_shuffled[:split_index], y_shuffled[split_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the Data Types\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "y_test = y_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True False False\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values\n",
    "print(np.isnan(X_train).any(), np.isnan(X_test).any(), np.isnan(y_train).any(), np.isnan(y_test).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN values if they exist\n",
    "X_train = np.nan_to_num(X_train)\n",
    "X_test = np.nan_to_num(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "747737/747737 [==============================] - 252s 336us/step - loss: 14.9898 - accuracy: 0.9553 - val_loss: 15.7047 - val_accuracy: 0.7894\n",
      "Epoch 2/10\n",
      "747737/747737 [==============================] - 246s 329us/step - loss: 13.9333 - accuracy: 0.9718 - val_loss: 7.0521 - val_accuracy: 0.9895\n",
      "Epoch 3/10\n",
      "747737/747737 [==============================] - 242s 324us/step - loss: 14.6801 - accuracy: 0.9747 - val_loss: 22.9600 - val_accuracy: 0.9838\n",
      "Epoch 4/10\n",
      "747737/747737 [==============================] - 244s 326us/step - loss: 15.2465 - accuracy: 0.9762 - val_loss: 10.6507 - val_accuracy: 0.9886\n",
      "Epoch 5/10\n",
      "747737/747737 [==============================] - 247s 330us/step - loss: 15.6627 - accuracy: 0.9771 - val_loss: 9.9479 - val_accuracy: 0.9898\n",
      "Epoch 6/10\n",
      "747737/747737 [==============================] - 243s 325us/step - loss: 16.0566 - accuracy: 0.9777 - val_loss: 5.3509 - val_accuracy: 0.9930\n",
      "Epoch 7/10\n",
      "747737/747737 [==============================] - 242s 324us/step - loss: 16.3442 - accuracy: 0.9782 - val_loss: 12.8387 - val_accuracy: 0.9887\n",
      "Epoch 8/10\n",
      "747737/747737 [==============================] - 240s 321us/step - loss: 16.6134 - accuracy: 0.9785 - val_loss: 9.1693 - val_accuracy: 0.9903\n",
      "Epoch 9/10\n",
      "747737/747737 [==============================] - 242s 323us/step - loss: 16.8335 - accuracy: 0.9788 - val_loss: 21.6938 - val_accuracy: 0.9851\n",
      "Epoch 10/10\n",
      "747737/747737 [==============================] - 241s 323us/step - loss: 17.1002 - accuracy: 0.9790 - val_loss: 82.8259 - val_accuracy: 0.9749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x15e47cd60>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model building using TensorFlow\n",
    "model = Sequential()\n",
    "model.add(Dense(1, activation='sigmoid', input_shape=(X_train.shape[1],)))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Return value to the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/eduardoangeli/Documents/GitHub/smartcredit/TF_model.ipynb Cell 12\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/eduardoangeli/Documents/GitHub/smartcredit/TF_model.ipynb#X11sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\u001b[39mGenerated user with:\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/eduardoangeli/Documents/GitHub/smartcredit/TF_model.ipynb#X11sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mHome Ownership: \u001b[39m\u001b[39m{\u001b[39;00mhome_ownership\u001b[39m}\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/eduardoangeli/Documents/GitHub/smartcredit/TF_model.ipynb#X11sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mAnnual Income: $\u001b[39m\u001b[39m{\u001b[39;00mannual_inc\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/eduardoangeli/Documents/GitHub/smartcredit/TF_model.ipynb#X11sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/eduardoangeli/Documents/GitHub/smartcredit/TF_model.ipynb#X11sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39mPrediction: Loan REJECTED\u001b[39m\u001b[39m\"\"\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/eduardoangeli/Documents/GitHub/smartcredit/TF_model.ipynb#X11sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39m# Calling the function\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/eduardoangeli/Documents/GitHub/smartcredit/TF_model.ipynb#X11sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m generate_random_user_predict(model, X_train, scaler)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scaler' is not defined"
     ]
    }
   ],
   "source": [
    "def generate_random_user_predict(model, X_train, scaler):\n",
    "    \"\"\"Generate a random example of a new user and predict loan acceptance.\"\"\"\n",
    "    \n",
    "    # Randomly select values for each feature\n",
    "    home_ownership = np.random.choice(['MORTGAGE', 'RENT', 'OWN'])\n",
    "    annual_inc = np.random.uniform(20000, 150000)  # Random income between 20k and 150k\n",
    "    loan_amnt = np.random.uniform(500, 40000)  # Random loan amount between $500 and $40k\n",
    "    dti = np.random.uniform(0.1, 0.9)  # Random dti between 10% and 90%\n",
    "    emp_length = np.random.choice(['< 1 year', '1 year', '2 years', '3 years', '4 years', '5 years',\n",
    "                                   '6 years', '7 years', '8 years', '9 years', '10+ years'])\n",
    "    \n",
    "    # Creating a DataFrame for the user\n",
    "    user_data = pd.DataFrame({\n",
    "        'home_ownership': [home_ownership],\n",
    "        'annual_inc': [annual_inc],\n",
    "        'loan_amnt': [loan_amnt],\n",
    "        'dti': [dti],\n",
    "        'emp_length': [emp_length]\n",
    "    })\n",
    "    \n",
    "    # One-hot encoding\n",
    "    user_encoded = pd.get_dummies(user_data, columns=['home_ownership', 'emp_length'])\n",
    "    \n",
    "    # Ensuring the user_encoded has all the columns that the model expects\n",
    "    # If not, they're filled with zeros (because of one-hot encoding)\n",
    "    missing_cols = set(X_train.columns) - set(user_encoded.columns)\n",
    "    for col in missing_cols:\n",
    "        user_encoded[col] = 0\n",
    "    user_encoded = user_encoded[X_train.columns]\n",
    "    \n",
    "    # Scaling the user data\n",
    "    user_scaled = scaler.transform(user_encoded)\n",
    "    \n",
    "    # Making prediction\n",
    "    prediction = classifier.predict(user_scaled)\n",
    "    \n",
    "    # Printing/Returning the result\n",
    "    if prediction[0] == 1:\n",
    "        print(f\"\"\"Generated user with:\n",
    "Home Ownership: {home_ownership}\n",
    "Annual Income: ${annual_inc:.2f}\n",
    "Loan Amount: ${loan_amnt:.2f}\n",
    "DTI: {dti*100:.2f}%\n",
    "Employment Length: {emp_length}\n",
    "\n",
    "Prediction: Loan ACCEPTED\"\"\")\n",
    "    else:\n",
    "        print(f\"\"\"Generated user with:\n",
    "Home Ownership: {home_ownership}\n",
    "Annual Income: ${annual_inc:.2f}\n",
    "Loan Amount: ${loan_amnt:.2f}\n",
    "DTI: {dti*100:.2f}%\n",
    "Employment Length: {emp_length}\n",
    "\n",
    "Prediction: Loan REJECTED\"\"\")\n",
    "\n",
    "# Calling the function\n",
    "generate_random_user_predict(model, X_train, scaler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
